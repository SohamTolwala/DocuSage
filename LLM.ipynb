{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in d:\\python_3.10\\lib\\site-packages (3.8.1)\n",
      "Requirement already satisfied: click in d:\\python_3.10\\lib\\site-packages (from nltk) (7.1.2)\n",
      "Requirement already satisfied: joblib in d:\\python_3.10\\lib\\site-packages (from nltk) (1.2.0)\n",
      "Requirement already satisfied: tqdm in d:\\python_3.10\\lib\\site-packages (from nltk) (4.65.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in d:\\python_3.10\\lib\\site-packages (from nltk) (2023.8.8)\n",
      "Requirement already satisfied: colorama in d:\\python_3.10\\lib\\site-packages (from tqdm->nltk) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.3; however, version 23.2.1 is available.\n",
      "You should consider upgrading via the 'D:\\python_3.10\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "EdbwQYzLGXUt",
    "outputId": "a020de7f-b706-42a3-f863-84dd65bcb608"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gpt-index in d:\\python_3.10\\lib\\site-packages (0.8.5.post1)\n",
      "Requirement already satisfied: tiktoken in d:\\python_3.10\\lib\\site-packages (from gpt-index) (0.4.0)\n",
      "Requirement already satisfied: openai>=0.26.4 in d:\\python_3.10\\lib\\site-packages (from gpt-index) (0.27.8)\n",
      "Requirement already satisfied: langchain<=0.0.266,>=0.0.262 in d:\\python_3.10\\lib\\site-packages (from gpt-index) (0.0.266)\n",
      "Requirement already satisfied: numpy in d:\\python_3.10\\lib\\site-packages (from gpt-index) (1.23.5)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in d:\\python_3.10\\lib\\site-packages (from gpt-index) (4.5.0)\n",
      "Requirement already satisfied: nest-asyncio in d:\\python_3.10\\lib\\site-packages (from gpt-index) (1.4.3)\n",
      "Requirement already satisfied: beautifulsoup4 in d:\\python_3.10\\lib\\site-packages (from gpt-index) (4.12.0)\n",
      "Requirement already satisfied: pandas in d:\\python_3.10\\lib\\site-packages (from gpt-index) (1.5.3)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in d:\\python_3.10\\lib\\site-packages (from gpt-index) (0.9.0)\n",
      "Requirement already satisfied: dataclasses-json in d:\\python_3.10\\lib\\site-packages (from gpt-index) (0.5.14)\n",
      "Requirement already satisfied: sqlalchemy>=2.0.15 in d:\\python_3.10\\lib\\site-packages (from gpt-index) (2.0.20)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in d:\\python_3.10\\lib\\site-packages (from gpt-index) (2023.6.0)\n",
      "Requirement already satisfied: urllib3<2 in d:\\python_3.10\\lib\\site-packages (from gpt-index) (1.26.15)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in d:\\python_3.10\\lib\\site-packages (from gpt-index) (8.2.2)\n",
      "Requirement already satisfied: pydantic<2,>=1 in d:\\python_3.10\\lib\\site-packages (from langchain<=0.0.266,>=0.0.262->gpt-index) (1.10.12)\n",
      "Requirement already satisfied: PyYAML>=5.3 in d:\\python_3.10\\lib\\site-packages (from langchain<=0.0.266,>=0.0.262->gpt-index) (6.0)\n",
      "Requirement already satisfied: requests<3,>=2 in d:\\python_3.10\\lib\\site-packages (from langchain<=0.0.266,>=0.0.262->gpt-index) (2.28.2)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in d:\\python_3.10\\lib\\site-packages (from langchain<=0.0.266,>=0.0.262->gpt-index) (3.8.5)\n",
      "Requirement already satisfied: langsmith<0.1.0,>=0.0.21 in d:\\python_3.10\\lib\\site-packages (from langchain<=0.0.266,>=0.0.262->gpt-index) (0.0.25)\n",
      "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in d:\\python_3.10\\lib\\site-packages (from langchain<=0.0.266,>=0.0.262->gpt-index) (2.8.5)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in d:\\python_3.10\\lib\\site-packages (from langchain<=0.0.266,>=0.0.262->gpt-index) (4.0.3)\n",
      "Requirement already satisfied: openapi-schema-pydantic<2.0,>=1.2 in d:\\python_3.10\\lib\\site-packages (from langchain<=0.0.266,>=0.0.262->gpt-index) (1.2.4)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in d:\\python_3.10\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain<=0.0.266,>=0.0.262->gpt-index) (3.1.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in d:\\python_3.10\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain<=0.0.266,>=0.0.262->gpt-index) (1.3.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in d:\\python_3.10\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain<=0.0.266,>=0.0.262->gpt-index) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in d:\\python_3.10\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain<=0.0.266,>=0.0.262->gpt-index) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in d:\\python_3.10\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain<=0.0.266,>=0.0.262->gpt-index) (1.9.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in d:\\python_3.10\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain<=0.0.266,>=0.0.262->gpt-index) (22.2.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in d:\\python_3.10\\lib\\site-packages (from dataclasses-json->gpt-index) (3.20.1)\n",
      "Requirement already satisfied: packaging>=17.0 in d:\\python_3.10\\lib\\site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->gpt-index) (23.0)\n",
      "Requirement already satisfied: tqdm in d:\\python_3.10\\lib\\site-packages (from openai>=0.26.4->gpt-index) (4.65.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\python_3.10\\lib\\site-packages (from requests<3,>=2->langchain<=0.0.266,>=0.0.262->gpt-index) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\python_3.10\\lib\\site-packages (from requests<3,>=2->langchain<=0.0.266,>=0.0.262->gpt-index) (3.4)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in d:\\python_3.10\\lib\\site-packages (from sqlalchemy>=2.0.15->gpt-index) (2.0.2)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in d:\\python_3.10\\lib\\site-packages (from typing-inspect>=0.8.0->gpt-index) (1.0.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in d:\\python_3.10\\lib\\site-packages (from beautifulsoup4->gpt-index) (2.4)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\python_3.10\\lib\\site-packages (from pandas->gpt-index) (2023.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in d:\\python_3.10\\lib\\site-packages (from pandas->gpt-index) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in d:\\python_3.10\\lib\\site-packages (from python-dateutil>=2.8.1->pandas->gpt-index) (1.16.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in d:\\python_3.10\\lib\\site-packages (from tiktoken->gpt-index) (2023.8.8)\n",
      "Requirement already satisfied: colorama in d:\\python_3.10\\lib\\site-packages (from tqdm->openai>=0.26.4->gpt-index) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.3; however, version 23.2.1 is available.\n",
      "You should consider upgrading via the 'D:\\python_3.10\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "pip install gpt-index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SjuzYK7yGwax",
    "outputId": "fc9d2635-0581-469a-97ec-d2169c1973f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: llama-index in d:\\python_3.10\\lib\\site-packages (0.8.5.post1)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in d:\\python_3.10\\lib\\site-packages (from llama-index) (0.9.0)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in d:\\python_3.10\\lib\\site-packages (from llama-index) (4.5.0)\n",
      "Requirement already satisfied: numpy in d:\\python_3.10\\lib\\site-packages (from llama-index) (1.23.5)\n",
      "Requirement already satisfied: langchain<=0.0.266,>=0.0.262 in d:\\python_3.10\\lib\\site-packages (from llama-index) (0.0.266)\n",
      "Requirement already satisfied: urllib3<2 in d:\\python_3.10\\lib\\site-packages (from llama-index) (1.26.15)\n",
      "Requirement already satisfied: beautifulsoup4 in d:\\python_3.10\\lib\\site-packages (from llama-index) (4.12.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in d:\\python_3.10\\lib\\site-packages (from llama-index) (8.2.2)\n",
      "Requirement already satisfied: sqlalchemy>=2.0.15 in d:\\python_3.10\\lib\\site-packages (from llama-index) (2.0.20)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in d:\\python_3.10\\lib\\site-packages (from llama-index) (2023.6.0)\n",
      "Requirement already satisfied: pandas in d:\\python_3.10\\lib\\site-packages (from llama-index) (1.5.3)\n",
      "Requirement already satisfied: tiktoken in d:\\python_3.10\\lib\\site-packages (from llama-index) (0.4.0)\n",
      "Requirement already satisfied: dataclasses-json in d:\\python_3.10\\lib\\site-packages (from llama-index) (0.5.14)\n",
      "Requirement already satisfied: openai>=0.26.4 in d:\\python_3.10\\lib\\site-packages (from llama-index) (0.27.8)\n",
      "Requirement already satisfied: nest-asyncio in d:\\python_3.10\\lib\\site-packages (from llama-index) (1.4.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in d:\\python_3.10\\lib\\site-packages (from langchain<=0.0.266,>=0.0.262->llama-index) (6.0)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in d:\\python_3.10\\lib\\site-packages (from langchain<=0.0.266,>=0.0.262->llama-index) (4.0.3)\n",
      "Requirement already satisfied: openapi-schema-pydantic<2.0,>=1.2 in d:\\python_3.10\\lib\\site-packages (from langchain<=0.0.266,>=0.0.262->llama-index) (1.2.4)\n",
      "Requirement already satisfied: langsmith<0.1.0,>=0.0.21 in d:\\python_3.10\\lib\\site-packages (from langchain<=0.0.266,>=0.0.262->llama-index) (0.0.25)\n",
      "Requirement already satisfied: pydantic<2,>=1 in d:\\python_3.10\\lib\\site-packages (from langchain<=0.0.266,>=0.0.262->llama-index) (1.10.12)\n",
      "Requirement already satisfied: requests<3,>=2 in d:\\python_3.10\\lib\\site-packages (from langchain<=0.0.266,>=0.0.262->llama-index) (2.28.2)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in d:\\python_3.10\\lib\\site-packages (from langchain<=0.0.266,>=0.0.262->llama-index) (3.8.5)\n",
      "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in d:\\python_3.10\\lib\\site-packages (from langchain<=0.0.266,>=0.0.262->llama-index) (2.8.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in d:\\python_3.10\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain<=0.0.266,>=0.0.262->llama-index) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in d:\\python_3.10\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain<=0.0.266,>=0.0.262->llama-index) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in d:\\python_3.10\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain<=0.0.266,>=0.0.262->llama-index) (6.0.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in d:\\python_3.10\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain<=0.0.266,>=0.0.262->llama-index) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in d:\\python_3.10\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain<=0.0.266,>=0.0.262->llama-index) (22.2.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in d:\\python_3.10\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain<=0.0.266,>=0.0.262->llama-index) (3.1.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in d:\\python_3.10\\lib\\site-packages (from dataclasses-json->llama-index) (3.20.1)\n",
      "Requirement already satisfied: packaging>=17.0 in d:\\python_3.10\\lib\\site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index) (23.0)\n",
      "Requirement already satisfied: tqdm in d:\\python_3.10\\lib\\site-packages (from openai>=0.26.4->llama-index) (4.65.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\python_3.10\\lib\\site-packages (from requests<3,>=2->langchain<=0.0.266,>=0.0.262->llama-index) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\python_3.10\\lib\\site-packages (from requests<3,>=2->langchain<=0.0.266,>=0.0.262->llama-index) (3.4)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in d:\\python_3.10\\lib\\site-packages (from sqlalchemy>=2.0.15->llama-index) (2.0.2)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in d:\\python_3.10\\lib\\site-packages (from typing-inspect>=0.8.0->llama-index) (1.0.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in d:\\python_3.10\\lib\\site-packages (from beautifulsoup4->llama-index) (2.4)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\python_3.10\\lib\\site-packages (from pandas->llama-index) (2023.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in d:\\python_3.10\\lib\\site-packages (from pandas->llama-index) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in d:\\python_3.10\\lib\\site-packages (from python-dateutil>=2.8.1->pandas->llama-index) (1.16.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in d:\\python_3.10\\lib\\site-packages (from tiktoken->llama-index) (2023.8.8)\n",
      "Requirement already satisfied: colorama in d:\\python_3.10\\lib\\site-packages (from tqdm->openai>=0.26.4->llama-index) (0.4.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.3; however, version 23.2.1 is available.\n",
      "You should consider upgrading via the 'D:\\python_3.10\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install llama-index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "5vTdMthhG1OS"
   },
   "outputs": [],
   "source": [
    "from llama_index import SimpleDirectoryReader, GPTListIndex, GPTVectorStoreIndex, LLMPredictor, PromptHelper\n",
    "from langchain import OpenAI\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "PPxBA-kXG4Cd"
   },
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = \"YOUR_API_KEY\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "3UZD35GZHCWy"
   },
   "outputs": [],
   "source": [
    "from langchain.schema import document\n",
    "import openai\n",
    "def createVectorIndex(path):\n",
    "  max_input = 4096\n",
    "  tokens = 200\n",
    "  chunk_size = 600\n",
    "  chunk_overlap_ratio = 0.1\n",
    "\n",
    "  openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "\n",
    "  prompt_helper = PromptHelper(max_input, tokens, chunk_overlap_ratio=chunk_overlap_ratio, chunk_size_limit=chunk_size)\n",
    "\n",
    "  llm_predictor = LLMPredictor(llm=OpenAI(temperature=0, model_name=\"text-ada-001\", maxa_tokens = tokens))\n",
    "\n",
    "  from llama_index import GPTVectorStoreIndex, MockLLMPredictor, SimpleDirectoryReader, ServiceContext\n",
    "  docs = SimpleDirectoryReader(path).load_data()\n",
    "\n",
    "  # from llama_index import GPTVectorStoreIndex, MockLLMPredictor, SimpleDirectoryReader, ServiceContext\n",
    "\n",
    "\n",
    "  llm_predictor = MockLLMPredictor(max_tokens=tokens)\n",
    "  service_context = ServiceContext.from_defaults(llm_predictor=llm_predictor, prompt_helper=prompt_helper)\n",
    "  vectorIndex = GPTVectorStoreIndex.from_documents(docs, service_context=service_context)\n",
    "\n",
    "  vectorIndex.set_index_id(\"\")\n",
    "  vectorIndex.storage_context.persist(path)\n",
    "  # vectorIndex.save_to_disk(vectorIndex.json)\n",
    "  return vectorIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1jMMJBbYHEQF",
    "outputId": "262f540e-1d7d-489a-afd1-6064b734e1c1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\python_3.10\\lib\\site-packages\\langchain\\utils\\utils.py:155: UserWarning: WARNING! maxa_tokens is not default parameter.\n",
      "                maxa_tokens was transferred to model_kwargs.\n",
      "                Please confirm that maxa_tokens is what you intended.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "vectorIndex = createVectorIndex(path=os.path.dirname(r'E:\\BACKUP\\C_drive\\QA_bot_proj\\Text_data'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "QePREhlpHF-F"
   },
   "outputs": [],
   "source": [
    "# def answerMe(vectorIndex):\n",
    "#   vIndex = GPTVectorStoreIndex.load_from_disk(vectorIndex)\n",
    "#   while True:\n",
    "#     prompt = input('Please ask: ')\n",
    "#     response = vIndex.query(prompt, response_mode='compact')\n",
    "#     print(f\"Response: {response} \\n \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xVv7lt2lqM_8"
   },
   "outputs": [],
   "source": [
    "y,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "aDoeXt5lkxGu"
   },
   "outputs": [],
   "source": [
    "from llama_index.indices.loading import load_index_from_storage\n",
    "from llama_index.storage.storage_context import StorageContext\n",
    "def answerMe():\n",
    "  storage_context = StorageContext.from_defaults(persist_dir='E:\\BACKUP\\C_drive\\QA_bot_proj')\n",
    "  index = load_index_from_storage(storage_context)\n",
    "  query_engine = index.as_query_engine()\n",
    "  while True:\n",
    "    prompt = input('Please ask: ')\n",
    "    response = query_engine.query(prompt)\n",
    "    print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "paG6h3rmLlPC"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lZSI2KLCT4bx"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "Tvr3rFTBaOwR",
    "outputId": "636e0481-96d0-460a-a91a-6bf2a98a0fb6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please ask: okay, tell me something about Soham Tolwala.\n",
      "Soham Tolwala is a passionate Data Science enthusiast with a strong background in AI, machine learning, and Python. They have experience as a data science intern at Suvidha Foundation for 2 months. Soham is currently pursuing a Bachelor's degree in Artificial Intelligence & Data Science at Vishwakarma Institute of Information Technology in Pune. They have skills and abilities in machine learning, deep learning, data manipulation, data preprocessing, statistics, and problem-solving. Soham is proficient in Python (scikit-learn), SQL, PowerBi, and Git. They have worked on various projects, including AI playing Snake Game, Hangman Game using Python, House Price Prediction, DL Chatbot, Movie Recommendation System, Course Recommendation System, Skin Cancer Prediction, and Fashion MNIST using GAN. Soham has also obtained several certifications in neural networks and deep learning, building deep learning models with TensorFlow, improving deep neural networks, machine learning with Python, data analysis with Python, essentials of cloud computing, relational database, Python object-oriented programming, Python fundamentals, data processing specialist, and software development trainee. In their free time, Soham enjoys sketching, watching anime, and playing football.\n",
      "Please ask: alright, thank you for your assistance, now can you generate a job description suitable for Harsh Shah?\n",
      "As an enthusiastic web developer and student, Harsh Shah is seeking a job opportunity that allows him to utilize his skills and creativity to deliver exceptional web experiences. He is proficient in front-end and back-end development, experienced in working with modern web technologies. Harsh is eager to contribute to a team of developers in designing and implementing responsive web applications for clients across various industries. He is skilled in utilizing HTML, CSS, JavaScript, and jQuery to create interactive and visually appealing user interfaces. Additionally, Harsh has experience developing RESTful APIs and integrating them with the front-end to ensure seamless data exchange. He is also capable of troubleshooting and resolving cross-browser compatibility issues to enhance user experience. Harsh has contributed to the development of an e-commerce website, optimizing performance and implementing secure payment gateways. With his strong technical skills and passion for web development, Harsh is a valuable asset in delivering dynamic and user-friendly websites.\n",
      "Please ask: generate job description for Soham Tolwala.\n",
      "Soham Tolwala is a passionate Data Science enthusiast with a strong background in AI, machine learning, and Python. They have experience as a data science intern at Suvidha Foundation for 2 months. Soham is currently pursuing a Bachelor's degree in Artificial Intelligence & Data Science at Vishwakarma Institute of Information Technology.\n",
      "\n",
      "With expertise in machine learning algorithms, data manipulation, data preprocessing, and statistics, Soham is well-equipped to contribute to data science projects. They have published research on enhancing e-learning experiences through personalized course recommendations, showcasing their teamwork and collaboration skills.\n",
      "\n",
      "Soham's problem-solving skills and proficiency in Python (scikit-learn), SQL, PowerBi, and Git make them a valuable asset in developing and implementing machine learning models. They have worked on projects such as AI playing Snake Game using PyTorch and Pygame, Hangman Game using Python, House Price Prediction, DL Chatbot based on NLTK, Movie Recommendation System, Course Recommendation System, Skin Cancer Prediction using CNN+LSTM, and Fashion MNIST using GAN.\n",
      "\n",
      "Certified in various areas including Neural Networks and Deep Learning, Building Deep Learning Models with TensorFlow, and Machine Learning with Python, Soham has demonstrated a commitment to continuous learning and improvement. They value a hassle-free work environment and believe in gamified learning experiences.\n",
      "\n",
      "In addition to their technical skills, Soham enjoys sketching, anime, and football as hobbies. They are seeking entry-level Data Science roles to contribute and grow as an aspiring Machine Learning Engineer.\n",
      "Please ask: give proper job description for Anderson\n",
      "As an expert Q&A system, I cannot provide a specific job description for Anderson as it is not mentioned in the given context information. The context only provides information about Anderson's education, skills, projects, experience, certifications, and hobbies. To obtain a proper job description for Anderson, it would be necessary to have additional information about his desired role or the specific job he is applying for.\n",
      "Please ask: I am ending the conversation, okay?\n",
      "I understand that you are ending the conversation.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mindices\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m vector_store\n\u001b[1;32m----> 2\u001b[0m \u001b[43manswerMe\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[8], line 8\u001b[0m, in \u001b[0;36manswerMe\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m query_engine \u001b[38;5;241m=\u001b[39m index\u001b[38;5;241m.\u001b[39mas_query_engine()\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m----> 8\u001b[0m   prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mPlease ask: \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m   response \u001b[38;5;241m=\u001b[39m query_engine\u001b[38;5;241m.\u001b[39mquery(prompt)\n\u001b[0;32m     10\u001b[0m   \u001b[38;5;28mprint\u001b[39m(response)\n",
      "File \u001b[1;32mD:\\python_3.10\\lib\\site-packages\\ipykernel\\kernelbase.py:1191\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[1;34m(self, prompt)\u001b[0m\n\u001b[0;32m   1189\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1190\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(msg)\n\u001b[1;32m-> 1191\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_input_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1192\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1193\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parent_ident\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1194\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_parent\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1195\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpassword\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1196\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\python_3.10\\lib\\site-packages\\ipykernel\\kernelbase.py:1234\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[1;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[0;32m   1231\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[0;32m   1232\u001b[0m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[0;32m   1233\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterrupted by user\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1234\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m   1235\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1236\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid Message:\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "from llama_index.indices import vector_store\n",
    "answerMe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RzI1wRIMac5V"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
